{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#importing libraries:\n",
    "-pandas\n",
    "-ascent\n",
    "-numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading bible csv's to dataframes for NLP processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Combined</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verse ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1 1:1</td>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Book Name Combined                                               Text\n",
       "Verse ID                                                                      \n",
       "1          Genesis    1 1:1  In the beginning God created the heavens and t..."
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asv_df = pd.read_csv(\"Resources/asv.csv\")\n",
    "asv_df['Combined'] = asv_df['Book Number'].astype(str) + \" \" + asv_df['Chapter'].astype(str) + \":\" + asv_df['Verse'].astype(str)\n",
    "asv_df.drop(['Chapter','Verse','Book Number'],axis=1, inplace=True)\n",
    "asv_df = asv_df[[\"Verse ID\",\"Book Name\",\"Combined\",\"Text\"]]\n",
    "asv_df.set_index(\"Verse ID\",inplace=True)\n",
    "asv_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['OriginalArabicText'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\BlackGod\\Desktop\\NWU_Bootcamp\\Project_3\\NLP_Bible\\NLP_bible.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BlackGod/Desktop/NWU_Bootcamp/Project_3/NLP_Bible/NLP_bible.ipynb#ch0000004?line=0'>1</a>\u001b[0m enq_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mResources/enq.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BlackGod/Desktop/NWU_Bootcamp/Project_3/NLP_Bible/NLP_bible.ipynb#ch0000004?line=1'>2</a>\u001b[0m enq_df[\u001b[39m\"\u001b[39m\u001b[39mVerse Number\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m6236\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BlackGod/Desktop/NWU_Bootcamp/Project_3/NLP_Bible/NLP_bible.ipynb#ch0000004?line=2'>3</a>\u001b[0m enq_df\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39mSrNo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mJuzNo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mSurahNo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mAyahNo\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mOriginalArabicText\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mArabicText\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mArabicWordCount\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mArabicLetterCount\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BlackGod/Desktop/NWU_Bootcamp/Project_3/NLP_Bible/NLP_bible.ipynb#ch0000004?line=3'>4</a>\u001b[0m enq_df\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:5287\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5285\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   5286\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 5287\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5288\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   5289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['OriginalArabicText'] not found in axis\""
     ]
    }
   ],
   "source": [
    "enq_df = pd.read_csv(\"Resources/enq.csv\")\n",
    "enq_df[\"Verse Number\"] = list(range(6236))\n",
    "del enq_df([\"SrNo\", \"JuzNo\", \"SurahNo\", \"AyahNo\", \"OriginalArabicText\",\"ArabicText\", \"ArabicWordCount\", \"ArabicLetterCount\"])\n",
    "enq_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Combined</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verse ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1 1:1</td>\n",
       "      <td>In the beginning God created the heaven and t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Book Name Combined                                               Text\n",
       "Verse ID                                                                      \n",
       "1          Genesis    1 1:1   In the beginning God created the heaven and t..."
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kjv_df = pd.read_csv(\"Resources/kjv.csv\", index_col=\"Verse ID\")\n",
    "kjv_df['Combined'] = kjv_df['Book Number'].astype(str) + \" \" + kjv_df['Chapter'].astype(str) + \":\" + kjv_df['Verse'].astype(str)\n",
    "kjv_df.drop(['Chapter','Verse','Book Number'],axis=1, inplace=True)\n",
    "kjv_df = kjv_df[[\"Book Name\",\"Combined\", \"Text\"]]\n",
    "kjv_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_df = pd.read_csv(\"Resources/web.csv\", index_col=\"Verse ID\")\n",
    "web_df['Combined'] = web_df['Book Number'].astype(str) + \" \" + web_df['Chapter'].astype(str) + \":\" + web_df['Verse'].astype(str)\n",
    "web_df.drop(['Chapter','Verse','Book Number'],axis=1, inplace=True)\n",
    "web_df = web_df[[\"Book Name\",\"Combined\", \"Text\"]]\n",
    "web_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = 'en_core_web_sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding spacy model and the sentencizer and asent/textblob pipelines\n",
    "nlp = spacy.load(spacy_model)\n",
    "nlp.add_pipe('sentencizer')\n",
    "nlp.add_pipe('asent_en_v1')\n",
    "nlp.add_pipe('spacytextblob')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_sentiments_asv = list(nlp.pipe(asv_df.Text.astype(str)))\n",
    "asv_df[\"sentiment_asent\"] = [verse_nlp._.polarity.compound for verse_nlp in verse_sentiments_asv]\n",
    "asv_df['sentiment_textblob'] = [verse_nlp._.blob.polarity for verse_nlp in verse_sentiments_asv]\n",
    "asv_df['average_sentiment'] = asv_df[[\"sentiment_asent\", \"sentiment_textblob\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_sentiments_asv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_sentiments_kjv = list(nlp.pipe(kjv_df.Text.astype(str)))\n",
    "kjv_df[\"sentiment_asent\"] = [verse_nlp._.polarity.compound for verse_nlp in verse_sentiments_kjv]\n",
    "kjv_df['sentiment_textblob'] = [verse_nlp._.blob.polarity for verse_nlp in verse_sentiments_kjv]\n",
    "kjv_df['average_sentiment'] = kjv_df[[\"sentiment_asent\", \"sentiment_textblob\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_sentiments_web = list(nlp.pipe(web_df.Text.astype(str)))\n",
    "web_df[\"sentiment_asent\"] = [verse_nlp._.polarity.compound for verse_nlp in verse_sentiments_web]\n",
    "web_df['sentiment_textblob'] = [verse_nlp._.blob.polarity for verse_nlp in verse_sentiments_web]\n",
    "web_df['average_sentiment'] = web_df[[\"sentiment_asent\", \"sentiment_textblob\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_sentiments_enq = list(nlp.pipe(enq_df.Text.astype(str)))\n",
    "enq_df[\"sentiment_asent\"] = [verse_nlp._.polarity.compound for verse_nlp in verse_sentiments_enq]\n",
    "enq_df['sentiment_textblob'] = [verse_nlp._.blob.polarity for verse_nlp in verse_sentiments_enq]\n",
    "enq_df['average_sentiment'] = enq_df[[\"sentiment_asent\", \"sentiment_textblob\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_df.columns.str.lower()\n",
    "kjv_df.columns.str.lower()\n",
    "web_df.columns.str.lower()\n",
    "enq_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sentiment_asv_df = asv_df.groupby(\"Book Name\", sort=False).mean()\n",
    "average_sentiment_kjv_df = kjv_df.groupby(\"Book Name\", sort=False).mean()\n",
    "average_sentiment_web_df = web_df.groupby(\"Book Name\", sort=False).mean()\n",
    "#average_sentiment_enq_df = enq_df.groupby(\"verse_binned\", sort=False).mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_sent_kjv_noindex = average_sentiment_kjv_df.reset_index()\n",
    "av_sent_asv_noindex = average_sentiment_asv_df.reset_index()\n",
    "av_sent_web_noindex = average_sentiment_web_df.reset_index()\n",
    "#av_sent_enq_noindex = average_sentiment_enq_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kjv_sent_plot = av_sent_kjv_noindex.plot(x=\"Book Name\", y=[\"average_sentiment\",\"sentiment_asent\",\"sentiment_textblob\"],ylim=(-.5,.5), kind='bar', figsize=(30,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_sent_plot = av_sent_web_noindex.plot(x=\"Book Name\", y=[\"average_sentiment\",\"sentiment_asent\",\"sentiment_textblob\"], kind='bar', figsize=(30,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_sent_plot = av_sent_asv_noindex.plot(x=\"Book Name\", y=[\"average_sentiment\",\"sentiment_asent\",\"sentiment_textblob\"], kind = 'bar', figsize=(30,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_sent_enq_noindex_binned.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_sent_enq_noindex['verse_binned'] = pd.qcut(av_sent_enq_noindex[\"Verse Number\"],q=66)\n",
    "av_sent_enq_noindex_binned = av_sent_enq_noindex.groupby(\"verse_binned\", sort=False).mean()\n",
    "enq_sent_plot = av_sent_enq_noindex_binned.plot(x=\"index\", y=[\"average_sentiment\",\"sentiment_asent\",\"sentiment_textblob\"], kind='bar', figsize=(30,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=300,\n",
    "                          max_font_size=90, \n",
    "                          random_state=0\n",
    "                         ).generate(str(asv_df['Text']))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(\"asv_wordcloud.png\", dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=30,\n",
    "                          max_font_size=100, \n",
    "                          random_state=0\n",
    "                         ).generate(str(kjv_df['Text']))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(\"kjv_wordcloud.png\", dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=30,\n",
    "                          max_font_size=100, \n",
    "                          random_state=0\n",
    "                         ).generate(str(web_df['Text']))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(\"web_wordcloud.png\", dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=30,\n",
    "                          max_font_size=100, \n",
    "                          random_state=0\n",
    "                         ).generate(str(enq_df['Text']))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(\"enq_wordcloud.png\", dpi=900)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e13a2bd7e601ba20958ae880a71f2cd8b54869ebdd5c69f34de7dded58785d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
